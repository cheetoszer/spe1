{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, CollectionConfig, HnswConfig, OptimizersConfig\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction load & chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_text_files(directory: str):\n",
    "    \"\"\"\n",
    "    Charge tout le contenu des fichiers .txt dans un dossier.\n",
    "    \"\"\"\n",
    "    texts = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "                texts[filename] = file.read()\n",
    "    return texts\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def chunk_text_by_headers(text: str):\n",
    "    \"\"\"\n",
    "    Découpe un texte en chunks basés sur les sections délimitées par \"#\".\n",
    "    \n",
    "    Chaque section démarre par un \"#\". Le texte à l'intérieur de chaque section est\n",
    "    ensuite regroupé en un seul chunk, avec le caractère \"#\" supprimé.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Le texte à découper.\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Liste de chunks cohérents.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    sections = text.split(\"#\")\n",
    "    \n",
    "    for section in sections:\n",
    "        if section.strip():\n",
    "            chunks.append(section)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_chunks(chunks, output_directory, filename_base):\n",
    "    \"\"\"\n",
    "    Sauvegarde les chunks dans des fichiers .txt séparés.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): Liste de chunks à sauvegarder.\n",
    "        output_directory (str): Dossier de destination des fichiers.\n",
    "        filename_base (str): Base du nom de fichier pour chaque chunk.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        output_path = os.path.join(output_directory, f\"{filename_base}_chunk_{idx + 1}.txt\")\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(chunk)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main_load_chunk(input_directory: str, output_directory: str):\n",
    "    \"\"\"\n",
    "    Charge les fichiers .txt, effectue le chunking et sauvegarde les chunks.\n",
    "    \n",
    "    Args:\n",
    "        input_directory (str): Dossier contenant les fichiers .txt à traiter.\n",
    "        output_directory (str): Dossier où sauvegarder les chunks générés.\n",
    "    \n",
    "    Returns:\n",
    "        List[List[str]]: Liste de listes, chaque sous-liste contient les chunks pour un document.\n",
    "    \"\"\"\n",
    "\n",
    "    texts = load_text_files(input_directory)\n",
    "\n",
    "    all_chunks = [] \n",
    "\n",
    "    for filename, text in texts.items():\n",
    "        print(f\"Chunking du fichier : {filename}\")\n",
    "        chunks = chunk_text_by_headers(text)\n",
    "        \n",
    "        all_chunks.append(chunks)\n",
    "        \n",
    "        filename_base = os.path.splitext(filename)[0]\n",
    "        save_chunks(chunks, output_directory, filename_base)\n",
    "    \n",
    "    return all_chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger et chunker les docs txt dans \"documents\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking du fichier : rules.txt\n",
      "Chunking du fichier : faq.txt\n"
     ]
    }
   ],
   "source": [
    "input_directory = \"documents\"  # Répertoire contenant les fichiers .txt\n",
    "output_directory = \"chunks\"    # Répertoire où sauvegarder les chunks\n",
    "all_chunks = main_load_chunk(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Fonctionnement :\\nLe joueur se déplace sur une grille à l'aide de bouton (haut, bas, gauche, droite) et résoud des problèmes mathématiques. Le but est d'atteindre une cible tout en répondant correctement aux questions mathématiques.\\n\\n\",\n",
       "  \"Mécaniques de jeu :\\nLe joueur commence au niveau 1. La grille de jeu s'agrandit au fur et à mesure des niveaux. Il y a différents types d'opérations mathématiques : addition, soustraction, multiplication, division, puissances, problèmes algébriques.\\n\\n\",\n",
       "  \"Système de score :\\nLe joueur gagne des points en répondant correctement aux questions. Le temps de réponse est pris en compte, une jauge de progression est présente. Les statistiques suivantes sont suivies : Nombre de réponses correctes, nombre total de tentatives, temps de réponse moyen, précision par type d'opération.\\n\\n\",\n",
       "  \"Progression :\\nLe jeu devient plus difficile au fur et à mesure que le niveau augmente. La difficulté augmente par : L'agrandissement de la grille, des opérations mathématiques plus complexes, des nombres plus grands dans les calculs.\\n\\n\",\n",
       "  \"Fin de partie :\\nLe jeu se termine quand le joueur ne parvient pas à atteindre l'objectif. Un tableau de bord est disponible pour voir ses performances, les statistiques sont analysées pour donner des retours sur : La mémoire de travail, la vitesse de traitement, La reconnaissance des motifs, la flexibilité cognitive, la résolution de problèmes, le contrôle de l'attention.\"],\n",
       " ['Réponses aux questions sur les performances générales :\\nQ: \"Quel est mon taux de réussite global ?\"\\nR: \"Votre taux de réussite global est de 78%. C\\'est une belle performance qui montre une bonne maîtrise des concepts mathématiques. Sur vos 100 dernières tentatives, vous avez répondu correctement à 78 questions.\"\\nQ: \"Comment a évolué mon score au fil du temps ?\"\\nR: \"Votre progression est constante. Vous avez commencé avec un score moyen de 500 points par session, et vous atteignez maintenant régulièrement 850 points. C\\'est une amélioration de 70% sur les deux dernières semaines.\"\\nQ: \"Quel est mon niveau actuel et que dois-je faire pour progresser ?\"\\nR: \"Vous êtes actuellement au niveau 7, ce qui correspond à un niveau intermédiaire avancé. Pour atteindre le niveau 8, concentrez-vous sur réduire votre temps de réponse moyen qui est actuellement de 8 secondes à environ 6 secondes.\"\\n\\n',\n",
       "  'Réponses aux questions sur les compétences cognitives :\\nQ: \"Comment est ma mémoire de travail ?\"\\nR: \"Votre mémoire de travail est excellente, avec un score de 85/100. Vous excellez particulièrement dans la résolution de problèmes impliquant plusieurs étapes de calcul. Suggestion : essayez maintenant des exercices avec des nombres plus complexes pour continuer à progresser.\"\\nQ: \"Quelle est ma vitesse de traitement ?\"\\nR: \"Votre vitesse de traitement est de 4.2 secondes en moyenne par problème, ce qui vous place dans le top 30% des joueurs. Nous avons noté une amélioration constante, particulièrement sur les opérations d\\'addition et de soustraction.\"\\nQ: \"Comment est ma reconnaissance des motifs mathématiques ?\"\\nR: \"Votre reconnaissance des motifs est très développée (score 90/100). Vous identifiez rapidement les séquences numériques et les relations entre les nombres. C\\'est particulièrement visible dans les exercices algébriques.\"\\n\\n',\n",
       "  'Réponses aux questions sur les types d\\'opérations :   \\nQ: \"Dans quel type d\\'opération suis-je le plus performant ?\"\\nR: \"Vos meilleures performances sont en multiplication, avec un taux de réussite de 92%. Voici le classement de vos performances par type d\\'opération : multiplication : 92%, addition : 88%, soustraction : 85%, division : 76%, puissances : 70%.\"\\nQ: \"Quelles sont mes faiblesses en mathématiques ?\"\\nR: \"Les divisions et les puissances semblent être vos points d\\'amélioration principaux. Dans les divisions, vous avez tendance à prendre plus de temps (moyenne de 7.5 secondes contre 4.2 secondes pour les autres opérations) et votre taux d\\'erreur est plus élevé (24%).\"\\n\\n',\n",
       "  'Réponses aux questions d\\'amélioration :\\nQ: \"Quelles sont vos recommandations pour améliorer mes performances ?\"\\nR: \"Basé sur vos données, voici mes recommandations : concentrez-vous sur les divisions en particulier avec des nombres à 2 chiffres, pratiquez les calculs mentaux rapides pour réduire votre temps de réponse, essayez d\\'atteindre le niveau 8 en moins de temps en optimisant vos déplacements, travaillez sur les exercices de puissances qui sont actuellement votre point faible.\"\\nQ: \"Comment puis-je réduire mon temps de réponse ?\"\\nR: \"Pour réduire votre temps de réponse actuel de 6.5 secondes : utilisez des techniques de calcul mental comme la décomposition des nombres, pratiquez les tables de multiplication jusqu\\'à 12, faites des sessions d\\'entraînement chronométrées. Votre objectif devrait être d\\'atteindre 5 secondes par réponse.\"\\n\\n',\n",
       "  'Réponses aux questions d\\'analyse comparative :\\nQ: \"Comment se comparent mes performances actuelles à mes performances précédentes ?\"\\nR: \"Sur le dernier mois : Votre score moyen a augmenté de 650 à 850 (+30%), Votre temps de réponse a diminué de 8.5 à 6.5 secondes (-23%), Votre taux de réussite est passé de 70% à 78%. C\\'est une progression significative, particulièrement en termes de rapidité.\"\\n\\n',\n",
       "  'Réponses aux questions sur les statistiques détaillées :\\nQ: \"Peux-tu me donner une analyse détaillée de mes dernières sessions ?\"\\nR: \"Analyse des 10 dernières sessions : score moyen : 850 points, meilleur score : 1200 points (session n°7), niveau maximum atteint : 7, opérations les plus réussies : additions (92%), points à améliorer : divisions (76%), temps moyen par problème : 6.5 secondes, Pprogression globale : +15% par rapport à la semaine précédente.\"\\n\\n',\n",
       "  'Réponses aux questions de stratégie :\\nQ: \"Quelle stratégie devrais-je adopter pour améliorer mon score ?\"\\nR: \"Visez 5 secondes max par calcul simple, réservez plus de temps pour les divisions complexes, concentrez-vous d\\'abord sur la précision (>85%), augmentez progressivement votre vitesse, visez les multiplicateurs de score.\"\\n']]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction Database & Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject(chunk):\n",
    "    \"\"\"\n",
    "    Extrait le sujet d'un chunk en capturant le texte avant le premier \":\".\n",
    "\n",
    "    Cette fonction prend un texte brut (chunk) et identifie le texte situé avant \n",
    "    le premier caractère \":\" pour le définir comme le sujet principal du chunk. \n",
    "    Si aucun \":\" n'est trouvé, elle renvoie \"Sujet inconnu\".\n",
    "\n",
    "    Args:\n",
    "        chunk (str): Le texte brut du chunk.\n",
    "\n",
    "    Returns:\n",
    "        str: Le texte avant le premier \":\" ou \"Sujet inconnu\" si \":\" n'est pas présent.\n",
    "    \"\"\"\n",
    "    if \":\" in chunk:\n",
    "        return chunk.split(\":\", 1)[0].strip()\n",
    "    return \"Sujet inconnu\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_embedding_model(model_name=\"intfloat/multilingual-e5-large-instruct\"):\n",
    "    \"\"\"\n",
    "    Charge un modèle d'embeddings et son tokenizer depuis Hugging Face.\n",
    "\n",
    "    Cette fonction initialise un modèle de transformation (Transformer) \n",
    "    ainsi que son tokenizer à partir du hub Hugging Face. Le modèle est\n",
    "    automatiquement déplacé sur un GPU (CUDA) s'il est disponible.\n",
    "\n",
    "    Args:\n",
    "        model_name (str, optional): Le nom du modèle Hugging Face à charger.\n",
    "                                    Par défaut : \"intfloat/multilingual-e5-large-instruct\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: Un tuple contenant le tokenizer, le modèle, et l'appareil (CPU ou GPU).\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    return tokenizer, model, device\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vectorize_text(texts, tokenizer, model, device):\n",
    "    \"\"\"\n",
    "    Vectorise une liste de textes en utilisant un modèle d'embeddings.\n",
    "\n",
    "    Cette fonction utilise le modèle et le tokenizer fournis pour transformer \n",
    "    chaque texte en un vecteur d'embedding. Les vecteurs résultants sont calculés\n",
    "    en prenant la moyenne des représentations des tokens pour chaque texte.\n",
    "\n",
    "    Args:\n",
    "        texts (list of str): Une liste de textes à vectoriser.\n",
    "        tokenizer (AutoTokenizer): Le tokenizer associé au modèle.\n",
    "        model (AutoModel): Le modèle de transformation (Transformer) chargé.\n",
    "        device (str): L'appareil sur lequel exécuter les calculs (\"cuda\" ou \"cpu\").\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Un tableau numpy contenant les vecteurs d'embedding pour chaque texte.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_qdrant_collection(client, collection_name):\n",
    "    \"\"\"\n",
    "    Crée une collection dans Qdrant si elle n'existe pas déjà.\n",
    "\n",
    "    Cette fonction vérifie si une collection Qdrant portant le nom spécifié existe. \n",
    "    Si elle n'existe pas, elle est créée avec une configuration par défaut, \n",
    "    incluant les paramètres pour HNSW et les optimisations.\n",
    "\n",
    "    Args:\n",
    "        client (QdrantClient): Une instance de QdrantClient connectée à un serveur Qdrant.\n",
    "        collection_name (str): Le nom de la collection à créer.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.get_collection(collection_name)\n",
    "        print(f\"La collection '{collection_name}' existe déjà.\")\n",
    "    except Exception:\n",
    "        print(f\"Création de la collection '{collection_name}'...\")\n",
    "        hnsw_config = HnswConfig(m=16, ef_construct=200, full_scan_threshold=200).model_dump()\n",
    "        optimizer_config = OptimizersConfig(\n",
    "            deleted_threshold=0.5,\n",
    "            vacuum_min_vector_number=10000,\n",
    "            default_segment_number=5,\n",
    "            flush_interval_sec=30\n",
    "        ).model_dump()\n",
    "        vector_params = VectorParams(size=1024, distance=Distance.COSINE)\n",
    "\n",
    "        client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=vector_params,\n",
    "            hnsw_config=hnsw_config,\n",
    "            optimizers_config=optimizer_config\n",
    "        )\n",
    "        print(f\"Collection '{collection_name}' créée.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def insert_data_to_qdrant(client, collection_name, embeddings, ids, metadata, texts):\n",
    "    \"\"\"\n",
    "    Insère des données (embeddings, identifiants, métadonnées) dans une collection Qdrant.\n",
    "    Cette fonction associe des vecteurs d'embedding à des identifiants uniques et des \n",
    "    métadonnées, puis les insère dans une collection Qdrant existante.\n",
    "\n",
    "    Args:\n",
    "        client (QdrantClient): Une instance de QdrantClient connectée à un serveur Qdrant.\n",
    "        collection_name (str): Le nom de la collection dans laquelle insérer les données.\n",
    "        embeddings (numpy.ndarray): Un tableau numpy contenant les vecteurs d'embedding.\n",
    "        ids (list of int): Une liste d'identifiants uniques pour chaque vecteur.\n",
    "        metadata (list of dict): Une liste de dictionnaires contenant les métadonnées associées.\n",
    "        texts (list of str): Une liste des textes à insérer avec les métadonnées.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=[                            #liste de dictionnaires -> à bosser\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"vector\": embedding,\n",
    "                \"payload\": {**meta, \"texte\": text} \n",
    "            }\n",
    "            for id_, embedding, meta, text in zip(ids, embeddings, metadata, texts)\n",
    "        ]\n",
    "    )\n",
    "    print(f\"Les données ont été insérées dans la collection '{collection_name}'.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main_db_embedding(all_chunks, collection_name):\n",
    "    \"\"\"\n",
    "    Vectorise les chunks et les insère dans une collection Qdrant avec des métadonnées.\n",
    "\n",
    "    Cette fonction effectue les étapes suivantes :\n",
    "    1. Charge le modèle d'embedding et le client Qdrant.\n",
    "    2. Crée la collection Qdrant si elle n'existe pas.\n",
    "    3. Génère des métadonnées pour chaque chunk, incluant :\n",
    "        - La date de mise à jour.\n",
    "        - La catégorie (\"règles\" ou \"foire au question\").\n",
    "        - Le sujet extrait du chunk.\n",
    "    4. Vectorise les chunks en utilisant le modèle d'embedding.\n",
    "    5. Insère les vecteurs et les métadonnées dans Qdrant.\n",
    "\n",
    "    Args:\n",
    "        all_chunks (list of list of str): Une liste contenant deux listes de chunks :\n",
    "            - La première liste correspond aux \"règles\".\n",
    "            - La seconde liste correspond à la \"foire aux questions\".\n",
    "        collection_name (str): Le nom de la collection Qdrant cible.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    tokenizer, model, device = load_embedding_model()\n",
    "    client = QdrantClient(url=\"http://localhost:6333\")\n",
    "    create_qdrant_collection(client, collection_name)\n",
    "\n",
    "    today_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    metadata = []\n",
    "    texts = []\n",
    "\n",
    "    for idx, chunks in enumerate(all_chunks):\n",
    "        category = \"règles\" if idx == 0 else \"foire au question\"\n",
    "        \n",
    "        for chunk in chunks:\n",
    "            \n",
    "            subject = extract_subject(chunk)\n",
    "            \n",
    "            metadata.append({\n",
    "                \"mis à jour\": today_date,\n",
    "                \"catégorie\": category,\n",
    "                \"sujet\": subject\n",
    "            })\n",
    "            texts.append(chunk)  \n",
    "\n",
    "    embeddings = vectorize_text(texts, tokenizer, model, device)\n",
    "    ids = list(range(len(texts)))\n",
    "\n",
    "    insert_data_to_qdrant(client, collection_name, embeddings, ids, metadata, texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectoriser et envoyer les chunks dans la collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création de la collection 'GameRag'...\n",
      "Collection 'GameRag' créée.\n",
      "Les données ont été insérées dans la collection 'GameRag'.\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"GameRag\"\n",
    "main_db_embedding(all_chunks, collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
