{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheetos/Bureau/Rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Filter, MatchValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(model_name=\"intfloat/multilingual-e5-large-instruct\"):\n",
    "    \"\"\"\n",
    "    Charge le modèle d'embeddings et le tokenizer depuis Hugging Face.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    return tokenizer, model, device\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vectorize_query(query: str, tokenizer, model, device):\n",
    "    \"\"\"\n",
    "    Vectorise une requête utilisateur pour le retriever.\n",
    "    \"\"\"\n",
    "    query = f\"query: {query}\"\n",
    "\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        embedding = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    return embedding.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_qdrant(query_vector, client, collection_name, top_k=5):\n",
    "    \"\"\"\n",
    "    Effectue une recherche dans la collection Qdrant à partir d'un vecteur de requête.\n",
    "    \"\"\"\n",
    "    query_vector = query_vector[0].tolist()\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vector,\n",
    "        limit=top_k,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    for result in results:\n",
    "        payload = result.payload\n",
    "        chunk_text = payload.get(\"texte\", \"Texte non disponible\")\n",
    "        print(\"Chunk trouvé :\", chunk_text)\n",
    "        print(\"Sujet :\", payload.get(\"sujet\", \"Non spécifié\"))\n",
    "        print(\"Score :\", result.score)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main_retrieve(query: str, collection_name=\"GameRag\"):\n",
    "    \"\"\"\n",
    "    Charge le modèle, vectorise la requête et effectue la recherche dans Qdrant.\n",
    "    \"\"\"\n",
    "    tokenizer, model, device = load_embedding_model()\n",
    "\n",
    "    client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "    query_vector = vectorize_query(query, tokenizer, model, device)\n",
    "\n",
    "    results = search_qdrant(query_vector, client, collection_name)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk trouvé : Réponses aux questions sur les statistiques détaillées :\n",
      "Q: \"Peux-tu me donner une analyse détaillée de mes dernières sessions ?\"\n",
      "R: \"Analyse des 10 dernières sessions : score moyen : 850 points, meilleur score : 1200 points (session n°7), niveau maximum atteint : 7, opérations les plus réussies : additions (92%), points à améliorer : divisions (76%), temps moyen par problème : 6.5 secondes, Pprogression globale : +15% par rapport à la semaine précédente.\"\n",
      "\n",
      "\n",
      "Sujet : Réponses aux questions sur les statistiques détaillées\n",
      "Score : 0.86762697\n",
      "--------------------------------------------------\n",
      "Chunk trouvé : Système de score :\n",
      "Le joueur gagne des points en répondant correctement aux questions. Le temps de réponse est pris en compte, une jauge de progression est présente. Les statistiques suivantes sont suivies : Nombre de réponses correctes, nombre total de tentatives, temps de réponse moyen, précision par type d'opération.\n",
      "\n",
      "\n",
      "Sujet : Système de score\n",
      "Score : 0.8511298\n",
      "--------------------------------------------------\n",
      "Chunk trouvé : Fin de partie :\n",
      "Le jeu se termine quand le joueur ne parvient pas à atteindre l'objectif. Un tableau de bord est disponible pour voir ses performances, les statistiques sont analysées pour donner des retours sur : La mémoire de travail, la vitesse de traitement, La reconnaissance des motifs, la flexibilité cognitive, la résolution de problèmes, le contrôle de l'attention.\n",
      "Sujet : Fin de partie\n",
      "Score : 0.83894503\n",
      "--------------------------------------------------\n",
      "Chunk trouvé : Réponses aux questions d'analyse comparative :\n",
      "Q: \"Comment se comparent mes performances actuelles à mes performances précédentes ?\"\n",
      "R: \"Sur le dernier mois : Votre score moyen a augmenté de 650 à 850 (+30%), Votre temps de réponse a diminué de 8.5 à 6.5 secondes (-23%), Votre taux de réussite est passé de 70% à 78%. C'est une progression significative, particulièrement en termes de rapidité.\"\n",
      "\n",
      "\n",
      "Sujet : Réponses aux questions d'analyse comparative\n",
      "Score : 0.83612835\n",
      "--------------------------------------------------\n",
      "Chunk trouvé : Réponses aux questions sur les types d'opérations :   \n",
      "Q: \"Dans quel type d'opération suis-je le plus performant ?\"\n",
      "R: \"Vos meilleures performances sont en multiplication, avec un taux de réussite de 92%. Voici le classement de vos performances par type d'opération : multiplication : 92%, addition : 88%, soustraction : 85%, division : 76%, puissances : 70%.\"\n",
      "Q: \"Quelles sont mes faiblesses en mathématiques ?\"\n",
      "R: \"Les divisions et les puissances semblent être vos points d'amélioration principaux. Dans les divisions, vous avez tendance à prendre plus de temps (moyenne de 7.5 secondes contre 4.2 secondes pour les autres opérations) et votre taux d'erreur est plus élevé (24%).\"\n",
      "\n",
      "\n",
      "Sujet : Réponses aux questions sur les types d'opérations\n",
      "Score : 0.8292509\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36759/1427904616.py:41: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    }
   ],
   "source": [
    "a = main_retrieve(\"Quelles statistiques sont suivies pendant mes sessions de jeu ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
